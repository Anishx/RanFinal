{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project - Music Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAuthors : \"Troy M, Aneesh K\"\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Authors : \"Troy M, Aneesh K\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The code runs format conversions as well. We can convert from mp3 to wav to then generate data based on that**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **NOTE** : *Uncomment/comment the below 3-4 lines of code to install/skip necessary pip dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa numpy\n",
    "!pip install pydub\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### **NOTE** : *Brew only works in Mac. Not sure how to install ffmpeg on Windows from command prompt/Powershell, but brew can be installed in WSL2 on Windows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./testAudio/City_Montage.mp3\"\n",
    "output_folder = \"./converted/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./converted/cCity_Montage.wav'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "src = \"./testAudio/City_Montage.mp3\"\n",
    "dst = \"./converted/cCity_Montage.wav\"\n",
    "\n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# **Code** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_clips(audio_path, num_clips=3, clip_duration=30, exclude_duration=20):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    total_duration = librosa.get_duration(y=y, sr=sr) - 2 * exclude_duration\n",
    "    print(\"y :::: \", y)\n",
    "    print(\"sr :::: \", sr)\n",
    "    samples_per_clip = int(clip_duration * sr)\n",
    "    spectrograms = []\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i in range(num_clips):\n",
    "        start_time = random.uniform(exclude_duration, total_duration - clip_duration + exclude_duration)\n",
    "        \n",
    "        clip = y[int(start_time * sr):int((start_time + clip_duration) * sr)]\n",
    "        clip_filename = os.path.join(output_folder, f\"clip_{i+1}.wav\")\n",
    "        sf.write(clip_filename, clip, sr)\n",
    "        \n",
    "        spectrogram = librosa.feature.melspectrogram(y=clip, sr=sr)\n",
    "        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        spectrograms.append(spectrogram_db)\n",
    "\n",
    "    return spectrograms, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrograms(spectrograms, sr):\n",
    "    for i, spectrogram in enumerate(spectrograms):\n",
    "        plt.figure(figsize=(4.32, 2.88), dpi=100)\n",
    "        librosa.display.specshow(spectrogram, sr=sr, x_axis=None, y_axis=None)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'specto/spectrogram_{i+1}.png', bbox_inches='tight', pad_inches=0, dpi='figure')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ::::  [ 1.0924011e-03  1.8297948e-03  1.8947383e-03 ... -2.5777494e-05\n",
      " -3.7915495e-06 -1.1627777e-05]\n",
      "sr ::::  44100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_clips = 3\n",
    "    clip_duration = 30\n",
    "    selected_spectrograms, sr = select_random_clips(audio_path, num_clips, clip_duration)\n",
    "    plot_spectrograms(selected_spectrograms, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterNotebook",
   "language": "python",
   "name": "jupyternotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
